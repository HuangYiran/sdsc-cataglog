{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e1eb9a-d9f0-4885-8aed-58a2e464f513",
   "metadata": {
    "tags": []
   },
   "source": [
    "这个项目的主要目的是实现一个应用，它能够在获得用户输入的，当前面临的挑战的情况下输出对应的，有助于应对这个挑战的github工具。\n",
    "\n",
    "我们都知道现在流行的chatgpt在各个领域中表现出强大的知识储备。特别是在结合了bing搜索之后，更是能根据需求直接提供对应的网站。但是chatgpt存在一些局限性：\n",
    "1. ChatGPT知识在2021年9月之前的数据进行训练，因此没有办法提供这之后的信息。\n",
    "2. ChatGPT没有办法分析复杂的逻辑关系。\n",
    "3. ChatGPT不能列出引用来源，其可靠性基于来源信息的可靠性，这些来源可能本身是错误的、前后矛盾的，或者经过ChatGPT组合后出现错误或矛盾。\n",
    "\n",
    "以上三点，导致直接使用chatgpt没有办法完成本项目的目的。我们可以先看一下，在这个展示中，我们面对的是下列这个挑战：\n",
    "“Geht es darum, die Sicherheit von Radwegen zu ermitteln, ist das Forschungspotential riesig. Ziel des SDSC-BW-Projekts war es, dieses zu erkunden. Ob der zahlreichen Problematiken gestaltete sich bereits die Erstellung eines Rahmenwerks schwierig. An erster Stelle standen die vielfältigen, teils verwirrenden Datenquellen – darunter unterschiedliche Websites, die Daten auf ihre eigene Weise abspeichern.”\n",
    "\n",
    "使用chatgpt的结果：\n",
    "首先是使用bing得到的回复：\n",
    "\n",
    "<img src=\"./images/bing_result.png\" alt=\"feedback from bing search\" width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e78e7e-f1c9-454e-b4ba-4d08172bf6f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "我们可以看到，chaptgpt没办法给出有效的反馈，而它提供的网页和我们的目的也没有直接的关系。\n",
    "\n",
    "使用ChatGPT网页对话得到的反馈会好一些：\n",
    "\n",
    "<div style=\"display: inline-block;\"><img src=\"./images/chatgpt_result.png\" alt=\"feedback from chatgpt chatbot\" width=\"700\" height=\"500\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf6bb8-dd78-4268-a653-5b670b77010e",
   "metadata": {
    "tags": []
   },
   "source": [
    "虽然chatgpt4能总结出面临的挑战，但是所提供的工具针对性比较弱而且都是比较成熟的发展时间比较久了的。除此之外，会有很多额外的描述，使得回复看起来复杂。\n",
    "\n",
    "针对chatgpt出现的分析复杂输入能力不足，回复繁复，无法提供实时的工具以及提供的链接可能出现错误等个问题，我们进行应对的核心思想是：\n",
    "1. 分解需求，每次只对gpt进行简单的询问\n",
    "2. 对输出进行限制，使输出简介并和主题具有联系\n",
    "3. 使用github api获取最新github，保证工具的流行性和有效性\n",
    "\n",
    "下面开始展示我们的做法，首先是加载需要的包裹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f6688b-130a-431d-a127-bd2c2462a19e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from git_request import search_top_starred_repositories\n",
    "from gpt_request import get_response_from_chatgpt_with_context\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479fbe7b-cef2-459a-99a5-92343ebb69d5",
   "metadata": {},
   "source": [
    "其中git_request和gpt_request都是自定义的包裹，分别用于想github服务器申请github列表和请openai申请chatgpt服务。\n",
    "pandas是数据分析工具，request是网络访问工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9af270-3974-4054-965a-0a3445c39881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input the use case:  Geht es darum, die Sicherheit von Radwegen zu ermitteln, ist das Forschungspotential riesig. Ziel des SDSC-BW-Projekts war es, dieses zu erkunden. Ob der zahlreichen Problematiken gestaltete sich bereits die Erstellung eines Rahmenwerks schwierig. An erster Stelle standen die vielfältigen, teils verwirrenden Datenquellen – darunter unterschiedliche Websites, die Daten auf ihre eigene Weise abspeichern.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The theme of the use case is: Radwegsicherheit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_case = input(\"Please input the use case: \")\n",
    "\n",
    "# get the theme from the user case\n",
    "prompt = f\"What is the theme studied in the following use case, please answer only with a keyword less then 20 letter: {use_case}\"\n",
    "context = []\n",
    "response, context = get_response_from_chatgpt_with_context(prompt, context)\n",
    "print(f\"\\nThe theme of the use case is: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa85abf-d541-4b07-990d-592bbbe6fa50",
   "metadata": {
    "tags": []
   },
   "source": [
    "首先我们让gpt分析出对应输入的主题，我们看到gpt能够很好的完成这个工作。这里为了限制回答的简洁性，我们通过加入需求限制了gpt的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214ef94c-dcc7-4433-8d23-b9d66b8bc086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main challenge facing are: \n",
      "Multiple data sources, confusing data, complex framework.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the challenge from the user case\n",
    "prompt = f\"According to the given description, what is the main problem faced by this study, please answer with 3 keywords and without explanation\"\n",
    "response, context = get_response_from_chatgpt_with_context(prompt, context)\n",
    "print(f\"The main challenge facing are: \\n{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805714c-1297-4cc1-a8b2-640700cf8956",
   "metadata": {},
   "source": [
    "然后我们要求在给定主题的情况下，总结出面临的三个挑战。因为这个挑战要应用于后续的github搜索，我们要求gpt使用关键字回复，并且不用给出解释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e932e864-ec26-40f4-9061-a0a6f6bf216a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraping is needed to extract and collect data from various online sources, including websites, in order to obtain a comprehensive dataset for analyzing and assessing the safety of bike lanes.\n",
      "For this, we recommend the following tools:\n",
      "Repository URL: https://github.com/khuyentran1401/Data-science\n",
      "README URL: https://github.com/khuyentran1401/Data-science/blob/master/README.md\n",
      "Repository URL: https://github.com/stanfordjournalism/search-script-scrape\n",
      "README URL: https://github.com/stanfordjournalism/search-script-scrape/blob/master/README.md\n",
      "Repository URL: https://github.com/hhursev/recipe-scrapers\n",
      "README URL: https://github.com/hhursev/recipe-scrapers/blob/master/README.md\n",
      "Repository URL: https://github.com/scrapy/parsel\n",
      "README URL: https://github.com/scrapy/parsel/blob/master/README.md\n",
      "Repository URL: https://github.com/damklis/DataEngineeringProject\n",
      "README URL: https://github.com/damklis/DataEngineeringProject/blob/master/README.md\n",
      "--------------------------------------------------\n",
      "Data integration is required to consolidate and harmonize the extracted data from different sources and formats with different levels of quality and completeness. The integrated dataset enables a more accurate and comprehensive analysis of the bike lane safety.\n",
      "For this, we recommend the following tools:\n",
      "Repository URL: https://github.com/airbytehq/airbyte\n",
      "README URL: https://github.com/airbytehq/airbyte/blob/master/README.md\n",
      "Repository URL: https://github.com/mage-ai/mage-ai\n",
      "README URL: https://github.com/mage-ai/mage-ai/blob/master/README.md\n",
      "Repository URL: https://github.com/django-import-export/django-import-export\n",
      "README URL: https://github.com/django-import-export/django-import-export/blob/master/README.md\n",
      "Repository URL: https://github.com/lancedb/lance\n",
      "README URL: https://github.com/lancedb/lance/blob/master/README.md\n",
      "Repository URL: https://github.com/cdapio/cdap\n",
      "README URL: https://github.com/cdapio/cdap/blob/master/README.md\n",
      "--------------------------------------------------\n",
      "Data analysis is essential to interpret and visualize the integrated and harmonized data. It provides insights into the safety of the bike lanes, identifies the problem areas, and enables policymakers to make data-driven decisions to improve the safety of bike lanes.\n",
      "For this, we recommend the following tools:\n",
      "Repository URL: https://github.com/fighting41love/funNLP\n",
      "README URL: https://github.com/fighting41love/funNLP/blob/master/README.md\n",
      "Repository URL: https://github.com/pandas-dev/pandas\n",
      "README URL: https://github.com/pandas-dev/pandas/blob/master/README.md\n",
      "Repository URL: https://github.com/wesm/pydata-book\n",
      "README URL: https://github.com/wesm/pydata-book/blob/master/README.md\n",
      "Repository URL: https://github.com/davisking/dlib\n",
      "README URL: https://github.com/davisking/dlib/blob/master/README.md\n",
      "Repository URL: https://github.com/tangyudi/Ai-Learn\n",
      "README URL: https://github.com/tangyudi/Ai-Learn/blob/master/README.md\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ask for keywords for python tools\n",
    "prompt = f\"I want to search for python tools for the above problem by keywords, what keywords should I use, please give me 3 suggestions and speperate them with semicolon, without explanation\"\n",
    "response, context = get_response_from_chatgpt_with_context(prompt, context)\n",
    "keywords = response.split(\";\")\n",
    "\n",
    "# list the advised git repos\n",
    "for keyword in keywords:\n",
    "    prompt = f\"Please explain why data {keyword} is needed in the context of the use case above, and please answer in less than 50 words\"\n",
    "    response, context = get_response_from_chatgpt_with_context(prompt, context)\n",
    "    print(response)\n",
    "\n",
    "    git_urls, readme_urls = search_top_starred_repositories(keyword+' python')\n",
    "    if git_urls is not None:\n",
    "        print(\"For this, we recommend the following tools:\")\n",
    "        for git_url, readme_url in zip(git_urls, readme_urls):\n",
    "            print(\"Repository URL:\", git_url)\n",
    "            print(\"README URL:\", readme_url)\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4863475-ddba-4e10-95e8-84aeee5f98b7",
   "metadata": {},
   "source": [
    "根据上面提供的每个关键字，我们从github服务器中寻找相匹配的工具，并根据其被应用的广泛性进行排序返回排名前5的结果。因为返回的结果都是通过github服务器提供的这保证了结果的可靠性。另外，因为我们是通过总结出的关键字进行匹配的，这使得得到的结果和我们的研究主题联系紧密。\n",
    "\n",
    "github关键字搜索的依据是一下三点：\n",
    "1. repository的名字和描述\n",
    "2. source code和file contents\n",
    "3. issue\n",
    "\n",
    "这保证了，尽管在repository主人关键字设置出错的情况下，也能搜索到对应的repository。同时，因为关键字是由chatgpt总结出来的，这保证了得到的关键字不会出现生僻的单词。\n",
    "\n",
    "当然，上述操作也存在缺点。比如，要求关键字必须在repository内容中出现；必须连接网络。\n",
    "\n",
    "第一个问题我们可以通过word embedding解决。通过对关键字和repository的readme文件进行word embedding，我们可以通过比较这两个embedding的相似性来找到匹配的仓库。第二个问题可以通过本地部署gpt来解决。openai的chatgpt-4虽然还没有开源，但是已经有很多开源的替代产品。我们可以通过本地部署这些替代产品来实现我们的目的。\n",
    "\n",
    "为此我们先加载两个自定义的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dddad50-6e33-43b0-a751-d583e306faf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from generate_local_github_database import download_and_save_git_stared_reposiories\n",
    "from git_request import search_top_related_local_repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ef818-ca54-4e3a-b916-8c4bd3b08850",
   "metadata": {
    "tags": []
   },
   "source": [
    "download_and_save_git_stared_reposiories实现了下载指定repository信息并保存到本地的操作，search_top_related_local_repositories实现了本地gpt的部署，word embedding的实现和本地数据库的搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c523dca-d08e-4e3a-ac18-163bdc718646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web scraping is necessary to collect data from various online sources, including websites, for analyzing the safety of bike lanes. It automates the data collection process and creates a comprehensive dataset for further analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/kit/tm/hj7422/conda/envs/vicuna/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n",
      "Unable to connect optimized C data functions [No module named 'clickhouse_connect.driverc.buffer'], falling back to pure Python\n",
      "Unable to connect ClickHouse Connect C to Numpy API [No module named 'clickhouse_connect.driverc.npconv'], falling back to pure Python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this, we recommend the following tools:\n",
      "Repository URL: https://github.com/RaRe-Technologies/gensim\n",
      "README URL: https://github.com/RaRe-Technologies/gensim/blob/master/README.md\n",
      "Repository URL: https://github.com/explosion/sense2vec\n",
      "README URL: https://github.com/explosion/sense2vec/blob/master/README.md\n",
      "Repository URL: https://github.com/BrikerMan/Kashgari\n",
      "README URL: https://github.com/BrikerMan/Kashgari/blob/master/README.md\n",
      "Repository URL: https://github.com/gnes-ai/gnes\n",
      "README URL: https://github.com/gnes-ai/gnes/blob/master/README.md\n",
      "Repository URL: https://github.com/github/semantic\n",
      "README URL: https://github.com/github/semantic/blob/master/README.md\n",
      "--------------------------------------------------\n",
      "Data wrangling is necessary to clean, transform, and harmonize the extracted dataset from different online sources. It enables data cleaning, data manipulation, and integration to ensure consistency, quality, and accuracy of the data used for analyzing the safety of bike lanes.\n",
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n",
      "For this, we recommend the following tools:\n",
      "Repository URL: https://github.com/cpitclaudel/dBoost\n",
      "README URL: https://github.com/cpitclaudel/dBoost/blob/master/README.md\n",
      "Repository URL: https://github.com/amundsen-io/amundsen\n",
      "README URL: https://github.com/amundsen-io/amundsen/blob/master/README.md\n",
      "Repository URL: https://github.com/doccano/doccano\n",
      "README URL: https://github.com/doccano/doccano/blob/master/README.md\n",
      "Repository URL: https://github.com/dmlc/gluon-nlp\n",
      "README URL: https://github.com/dmlc/gluon-nlp/blob/master/README.md\n",
      "Repository URL: https://github.com/flairNLP/flair\n",
      "README URL: https://github.com/flairNLP/flair/blob/master/README.md\n",
      "--------------------------------------------------\n",
      "Data visualization is necessary to present the analyzed data in a clear and visually appealing format. It helps to identify trends, patterns, and insight to stakeholders, policymakers, and residents, promoting data-driven decision-making to improve the safety of bike lanes.\n",
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n",
      "For this, we recommend the following tools:\n",
      "Repository URL: https://github.com/PAIR-code/facets\n",
      "README URL: https://github.com/PAIR-code/facets/blob/master/README.md\n",
      "Repository URL: https://github.com/amundsen-io/amundsen\n",
      "README URL: https://github.com/amundsen-io/amundsen/blob/master/README.md\n",
      "Repository URL: https://github.com/bokeh/bokeh\n",
      "README URL: https://github.com/bokeh/bokeh/blob/master/README.md\n",
      "Repository URL: https://github.com/raghakot/keras-vis\n",
      "README URL: https://github.com/raghakot/keras-vis/blob/master/README.md\n",
      "Repository URL: https://github.com/yosinski/deep-visualization-toolbox\n",
      "README URL: https://github.com/yosinski/deep-visualization-toolbox/blob/master/README.md\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ask for keywords for python tools\n",
    "prompt = f\"I want to search for python tools for the above problem by keywords, what keywords should I use, please give me 3 suggestions and speperate them with semicolon, without explanation\"\n",
    "response, context = get_response_from_chatgpt_with_context(prompt, context)\n",
    "keywords = response.split(\";\")\n",
    "\n",
    "# list the advised git repos\n",
    "for keyword in keywords:\n",
    "    prompt = f\"Please explain why data {keyword} is needed in the context of the use case above, and please answer in less than 50 words\"\n",
    "    response, context = get_response_from_chatgpt_with_context(prompt, context)\n",
    "    print(response)\n",
    "\n",
    "    git_urls, readme_urls = search_top_related_local_repositories(keyword, database_path = './data/repositories.csv')\n",
    "    if git_urls is not None:\n",
    "        print(\"For this, we recommend the following tools:\")\n",
    "        for git_url, readme_url in zip(git_urls, readme_urls):\n",
    "            print(\"Repository URL:\", git_url)\n",
    "            print(\"README URL:\", readme_url)\n",
    "        print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf0244-8684-44a8-a301-554a12dbffe4",
   "metadata": {},
   "source": [
    "我们可以看到，在本地也能很好的完成工作。另外，因为我们适用的测试数据库只包含了两百个不同的repository而且种类比较集中，所以从结果上看，它的推荐结果没有联网的结果好。但是这点可以通过增加本地数据集解决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0746de5-8289-47ab-8a5b-cc22adddc193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalogenv",
   "language": "python",
   "name": "catalogenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
