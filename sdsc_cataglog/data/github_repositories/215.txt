repo_name: kserve
link: https://github.com/kserve/kserve
description: KServe provides a Kubernetes Custom Resource Definition for serving machine learning (ML) models on arbitrary frameworks. It enables a simple, pluggable, and complete story for production ML serving, including prediction, pre-processing, post-processing, and explainability. KServe encapsulates the complexity of autoscaling, networking, health checking, and server configuration to bring cutting-edge serving features like GPU autoscaling, Scale to Zero, and Canary Rollouts to your ML deployments. KServe is being used across various organizations and is an important add-on component of Kubeflow. Learn more about KServe, its supported features, and participate in the KServe community through its website documentation.
