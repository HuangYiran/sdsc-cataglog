{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158df75a-f87b-42ef-8c55-5bac0af4edbc",
   "metadata": {},
   "source": [
    "# Erstellen einer lokalen Github Datenbank\n",
    "\n",
    "Um lokale Anfragen machen zu können, muss zuerst eine lokale Datenbank erzeugt werden. Im folgenden wird gezeigt, wie diese Datenbank erzeugt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434348d5-3eeb-49a3-8bc1-3450740db484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from data_generation.generate_local_github_database import download_and_save_git_reposiories_according_to_keyword_without_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986cae0-a60f-4097-ac9c-5a4644f451b6",
   "metadata": {},
   "source": [
    "# Topics included\n",
    "Wir laden die Github-Tools aus einer Sammlung von Github-Repositories herunter, die auf den folgenden Schlüsselwörtern basieren. Für jedes Schlüsselwort werden 20 Tools heruntergeladen. Wir extrahieren die Informationen aller heruntergeladenen Tools und speichern sie in der Datei \"repositories_without_embd\" im Datenordner.\n",
    "Die extrahierten Informationen umfassen:\n",
    "- Link zum Werkzeug\n",
    "- Link zur Werkzeugbeschreibung\n",
    "- Vorverarbeitete Werkzeugbeschreibungen\n",
    "\n",
    "Laut Statistik gibt es im Mai 2021 170 Millionen verschiedene Repositories auf Github. Der Prozentsatz derer, die wir gespeichert haben, ist also im Verhältnis zur Gesamtzahl gering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0586eb9-b25c-439d-9ffb-0b7ad631b120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"data mining\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Image and Speech Recognition\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Natural Language Processing\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Fraud Detection\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Recommendation Systems\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Healthcare\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Plotting\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Dataset\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Tools\", num = 20, out_path = './data/repositories_without_embd.csv')\n",
    "df = download_and_save_git_reposiories_according_to_keyword_without_embedding(keyword = \"Reinforcement Learning\", num = 20, out_path = './data/repositories_without_embd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1948de-f27f-4dfc-86a0-75be6c7540e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/repositories_without_embd.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930a8c7-2959-445a-bf5c-981ff30d4f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa40e9d-8996-4565-8a53-904ddbf80828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([df]*10).reset_index().iloc[:, 1:].to_csv(\"data/copydata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9614123f-088b-48c5-9f9a-141b530fea4a",
   "metadata": {},
   "source": [
    "# Erzeugung der Wordembeddings\n",
    "\n",
    "Wordembeddings sind eine Technik des maschinellen Lernens, die verwendet wird, um Wörter oder Sätze in einem Vektorraum darzustellen. Diese Darstellung ermöglicht es, semantische Beziehungen zwischen Wörtern zu erfassen, indem ähnliche Wörter nahe beieinander liegen. Ein häufig verwendetes Modell zur Erzeugung von Wordembeddings ist Word2Vec.\n",
    "\n",
    "Die grundlegende Idee hinter Wordembeddings besteht darin, dass Wörter, die in ähnlichen Kontexten auftreten, ähnliche Vektordarstellungen erhalten. Zum Beispiel könnten die Wörter \"Katze\" und \"Hund\" ähnliche Vektoren haben, da sie oft in ähnlichen Kontexten, wie \"Haustier\", \"Tierarzt\" usw., auftreten. Diese Vektordarstellungen sind in der Regel hochdimensional, wobei jede Dimension einem bestimmten Merkmal oder Kontext entspricht.\n",
    "\n",
    "Durch die Berechnung der Cosinus Similarity zwischen den Vektordarstellungen von zwei Wörtern oder Sätzen kann ihre semantische Ähnlichkeit bestimmt werden. Je näher die Kosinusähnlichkeitswert an 1 liegt, desto ähnlicher sind die Wörter oder Sätze.\n",
    "\n",
    "Im folgenden werden basierend auf der Beschreibung der Github Repositories Wordembeddings erzeugt und in der lokalen Datenbank hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294bcf48-1c2f-4669-a671-9cf6817f27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from localgpt_request import get_text_embedding_with_localgpt, get_docu_embedding_with_localgpt, get_docu_embedding_save_to_chroma_with_localgpt\n",
    "from gpt_request import get_text_embedding_with_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e04b2-5712-4061-a36a-65e2609cb1d2",
   "metadata": {},
   "source": [
    "## Anfragen mit dem Local GPT\n",
    "Das hier verwendete Modell ist instructor-xl. Die Modellgröße beträgt etwa 5G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea25a2-1da6-4ba8-81f7-1d5f6a46a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "get_docu_embedding_with_localgpt(df.iloc[:10, 2].values, model_name = \"hkunlp/instructor-xl\")\n",
    "end_time = time.time()\n",
    "use_time = end_time - start_time\n",
    "\n",
    "print(f\"Die Gesamtzeit für die Erstellung der ersten 10 Embeddings beträgt：{use_time}\")\n",
    "print(f\"Die durchschnittliche Zeit für die Erstellung der ersten 10 Embeddings beträgt：{use_time/10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bfec0-3c84-410d-8c77-e0a54a844326",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Anfragen mit dem OpenAI GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf89e01-2866-4f5a-ad5f-f24fa251f470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "list_time = []\n",
    "for i in range(10):\n",
    "    get_text_embedding_with_openai(df.iloc[i, 2])\n",
    "    end_time = time.time()\n",
    "    use_time = end_time - start_time\n",
    "    list_time.append(use_time)\n",
    "\n",
    "print(f\"Die Gesamtzeit für die Erstellung der ersten 10 Embeddings beträgt：{np.sum(list_time)}\")\n",
    "print(f\"Die durchschnittliche Zeit für die Erstellung der ersten 10 Embeddings betrug：{np.mean(list_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd0d3e-55c9-4e62-abb5-84cf3b1f9779",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beschleunigung mit Slurm\n",
    "Ein Problem beim Multithreading ist, dass das Laden des Modells in jedem Thread sehr viel Zeit in Anspruch nehmen kann. Dies kann zwar durch den Fork-Mechanismus gehandhabt werden, aber Fork unterstützt keine Cuda-Kontextkomplexität und kann zu Fehlern führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9c95d-5667-402e-afc8-9b25a593ee2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "sys.path.append(\"/pfs/data5/home/kit/tm/hj7422/2023_sdsc_catalog/sdsc-cataglog/sdsc-cataglog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f05cdc-9dce-4cdc-abc7-7e757ad8e135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit_slurm_job(script_file):\n",
    "    # Slurm-Befehl erstellen\n",
    "    cmd = './' + script_file  \n",
    "    \n",
    "    # Ausführen des Slurm-Befehls mit Hilfe des Subprozess-Moduls\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "    # Abfrage der Ausgabe einer Aufgabe, bis die Aufgabe abgeschlossen ist\n",
    "    while True:\n",
    "        output = proc.stdout.readline()\n",
    "        if output == b'' and proc.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.decode().strip())\n",
    "    \n",
    "    # Abrufen des Rückgabestatuscodes der Aufgabe\n",
    "    return_code = proc.poll()\n",
    "    print('Aufgabenrückgabe-Statuscode:', return_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b107903-2751-4015-9872-b462e30ea26c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_slurm_job('run_db/run_db_embd.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d385171d",
   "metadata": {},
   "source": [
    "# TODO Was passiert hier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529574b-5dcc-43f9-94b7-d8883d54f4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce321a87-829c-444d-bb2c-aacba143596a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = [\"DSADS\", \"HAPT\", \"OPPO\", \"PAMAP2\", \"RW\"], columns = [\"MCNN_base\", \"DCL_base\", \"Transformer_base\", \"MCNN_activityGAN\", \"DCL_activityGAN\", \"Transformer_activityGAN\", \"MCNN_optiHAR\", \"DCL_optiHAR\", \"Transformer_optiHAR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d4bc4-d288-45f8-8218-ea00d4bf9589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"MCNN_base\"] = [82.0, 78.6, 39.4, 69.8, 68.8]\n",
    "df[\"DCL_base\"] = [85.2, 80.3, 39.8, 73.4, 70.5]\n",
    "df[\"Transformer_base\"] = [80.4, 79.5, 38.7, 73.5, 68.2]\n",
    "df[\"MCNN_activityGAN\"] = [85.4, 81.0, 40.6, 72.6, 76.0]\n",
    "df[\"DCL_activityGAN\"] = [86.4, 81.5, 38.7, 76.6, 74.3]\n",
    "df[\"Transformer_activityGAN\"] = [83.5, 81.5, 38.7, 76.5, 74.2]\n",
    "df[\"MCNN_optiHAR\"] = [90.6, 83.2, 43.4, 79.2, 80.0]\n",
    "df[\"DCL_optiHAR\"] = [91.2, 84.8, 44.4, 78.9, 78.4]\n",
    "df[\"Transformer_optiHAR\"] = [87.5, 83.1, 45.5, 75.5, 75.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6285055-1e2b-4505-b9e5-7224c8096f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0519ab7-5e74-4e15-8807-498ba2bd6350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b0631-8682-4f5a-9481-f50f8c047342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对数据按行进行标准化\n",
    "df_normalized = df.div(df.max(axis=1), axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_normalized, annot=df, fmt='', cmap=\"YlGnBu\", cbar=False)\n",
    "#plt.show()\n",
    "plt.savefig(\"heatmap.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877169c-97e2-4d31-b635-73b16f0b9805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df, annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f4c8a-8586-4b4f-9460-db3946788aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.plot(kind='bar', figsize=(12, 8))\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Performance of Different Models and Methods on Different Datasets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd839c-12dd-4d4c-ad1b-dd03ea415fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# 先分离出模型和提升方法名称，使其更具可读性\n",
    "df.columns = pd.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# 为每个模型-提升方法组合创建一个新的条形图系列\n",
    "for model_method in df.columns:\n",
    "    fig.add_trace(go.Bar(\n",
    "        name='_'.join(model_method),\n",
    "        x=df.index,\n",
    "        y=df[model_method],\n",
    "        offsetgroup='_'.join(model_method),\n",
    "        hoverinfo='name+y'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Performance of Different Models and Methods on Different Datasets',\n",
    "    yaxis_title='Performance',\n",
    "    xaxis_title='Dataset',\n",
    "    barmode='group',  # 将每个数据集的模型-方法组合分组\n",
    "    bargap=0.15,      # 每个分组的间隔大小\n",
    "    bargroupgap=0.1   # 分组内条形图的间隔大小\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c2bad-0c2b-4c2a-8d55-28b20f9b424b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce58ac9-b915-4906-a9a4-25805e1c1ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade20b5c-1f42-4906-8e9d-e70776fd87d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = (df['MCNN_optiHAR']- df['MCNN_activityGAN'])/df['MCNN_activityGAN']\n",
    "b = (df['DCL_optiHAR']- df['DCL_activityGAN'])/df['DCL_activityGAN']\n",
    "c = (df['Transformer_optiHAR']- df['Transformer_activityGAN'])/df['Transformer_activityGAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174f0ec-0c57-4d9a-9827-5d9111f06e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(a+b+c)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483b249-3257-492a-b18d-094e564dd7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum([0.054783, 0.029094, 0.035954, 0.043575])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9cfcc-b75b-45d4-b3e7-f7c3bb9add61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c00175-9999-482b-9bb8-292805268fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_list = openml.datasets.list_datasets(output_format='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f7ab5-76d7-47be-be88-5e369e8eecf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd981b-26ce-4d8f-bd4c-7a2157d89609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_data_description(data_id):\n",
    "    url = f\"https://www.openml.org/api/v1/data/{data_id}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "# Specify the data_id of the dataset for which you want to retrieve the description\n",
    "data_id = 45578  # Example data_id, you should replace it with the actual ID of the dataset you want to retrieve\n",
    "\n",
    "data_description = get_data_description(data_id)\n",
    "print(data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3294c-a2a1-4d34-bffa-dbfc8b4628ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://www.openml.org/api/v1/data/2')\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d4b20-fa94-4990-89bd-600497885e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ad884-3e0b-472f-96a0-1bafb7d0220c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = openml.datasets.get_dataset(1)\n",
    "\n",
    "# 获取数据集的详细信息\n",
    "print(dataset.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e1457-5356-4fdc-8223-dca9324f72ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46e27f-aecf-4503-882b-18bac2a5e084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/openml_dataset_info.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8ab8a-62f1-4109-9127-7303ef71e623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e170716-a3ce-45ed-8b24-6eed905fbadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalogserver",
   "language": "python",
   "name": "catalogserver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
